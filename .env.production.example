# Production Environment Configuration for Render
# Copy these to your Render dashboard Environment Variables

# ============================================
# CRITICAL: Set these in Render Dashboard
# ============================================

# Application Configuration
APP_NAME=HealthLang AI MVP
APP_VERSION=0.1.0
DEBUG=false
ENVIRONMENT=production

# Server Configuration
HOST=0.0.0.0
PORT=8000
WORKERS=1
RELOAD=false
BACKEND_URL=https://healthlang-ai-mvp.onrender.com

# ============================================
# Database Configuration
# ============================================
# Get these from your Render PostgreSQL dashboard
# After creating the database, copy the "External Database URL"

# Production Database URL (REQUIRED - copy from Render PostgreSQL)
PROD_DATABASE_URL=postgresql://healthlang_user:YOUR_PASSWORD@dpg-xxxxx.oregon-postgres.render.com/healthlang_production

# Development Database (not used in production, but good to keep for reference)
DEV_DATABASE_URL=postgresql://healthlang:Abdulhameed123@localhost:5432/healthlang

# ============================================
# API Keys (REQUIRED)
# ============================================
GROQ_API_KEY=your_groq_api_key_here
GROQ_BASE_URL=https://api.groq.com/openai/v1
XAI_GROK_API_KEY=your_xai_api_key_here
XAI_GROK_BASE_URL=https://api.x.ai/v1
TAVILY_API_KEY=your_tavily_api_key_here

# ============================================
# MCP Server Configuration
# ============================================
MCP_SERVER_URL=https://healthcare-mcp.onrender.com

# ============================================
# LLM Configuration
# ============================================
LLM_PROVIDER=groq
GROQ_MODEL=meta-llama/llama-4-maverick-17b-128e-instruct
OPENAI_MODEL=gpt-3.5-turbo
LOCAL_MODEL=llama-3-8b
LLM_TIMEOUT=30

# GPU Configuration
USE_GPU=false
USE_MPS=false

# ============================================
# Vector Database Configuration
# ============================================
VECTOR_DB_TYPE=chroma
EMBEDDING_MODEL=sentence-transformers/all-MiniLM-L6-v2
CHROMA_DB_PATH=./data/chroma
CHROMA_PERSIST_DIRECTORY=./data/chroma

# ============================================
# RAG Configuration
# ============================================
RAG_ENABLED=true
MAX_RETRIEVAL_DOCS=3
SIMILARITY_THRESHOLD=0.75
KNOWLEDGE_BASE_PATH=./data/medical_knowledge/processed

# ============================================
# Security Configuration
# ============================================
SECRET_KEY=CHANGE_THIS_TO_A_SECURE_RANDOM_STRING_IN_PRODUCTION
ALGORITHM=HS256
ACCESS_TOKEN_EXPIRE_MINUTES=30
CORS_ORIGINS=https://lang-heal-chat.vercel.app,https://your-frontend-domain.com

# ============================================
# Rate Limiting
# ============================================
RATE_LIMIT_PER_MINUTE=120
RATE_LIMIT_PER_HOUR=2000

# ============================================
# Logging Configuration
# ============================================
LOG_LEVEL=INFO
LOG_FORMAT=json

# ============================================
# Medical Analysis Configuration
# ============================================
MEDICAL_MODEL_NAME=meta-llama/llama-4-maverick-17b-128e-instruct
MEDICAL_MODEL_PROVIDER=groq
MAX_TOKENS=2048
TEMPERATURE=0.1
TOP_P=0.9

# ============================================
# Translation Configuration
# ============================================
TRANSLATION_MODEL=meta-llama/Llama-4-Maverick-17B-128E-Instruct
TRANSLATION_PROVIDER=groq

# ============================================
# Monitoring (Optional)
# ============================================
PROMETHEUS_ENABLED=true
CACHE_TTL=7200
CACHE_MAX_SIZE=2000
